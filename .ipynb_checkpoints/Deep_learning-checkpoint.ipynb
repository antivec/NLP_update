{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('filtered_movieData.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = {'tfidf':TfidfVectorizer()}\n",
    "##term frequency - inverse document frequency \n",
    "classifier = {'ClassifierCV':CalibratedClassifierCV(), \n",
    "              'logistic_regression': LogisticRegression()\n",
    "             }\n",
    "\n",
    "genres = data.Genres.value_counts().reset_index()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_num = len(data.Overview)\n",
    "for i in range(max_num):\n",
    "        if type(data.Overview[i]) == float:\n",
    "            data.Overview[i] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vec = len(vectorizer)\n",
    "n_clf = len(classifier)\n",
    "\n",
    "n_iter = n_vec * n_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres[:9]:\n",
    "    data['genre_y'] = [1 if y == genre else 0 for y in data['Genres']]\n",
    "    k = 1\n",
    "    for vect_name, vect in vectorizer.items():\n",
    "        for clf_name, clf in classifier.items():\n",
    "#           print(genre.upper() + ' [' + str(k) + '/' +str(n_iter) + ']: ' + vect_name + ' - ' + clf_name )\n",
    "            kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "            pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "            \n",
    "            acc = []\n",
    "            prec = []\n",
    "            rec = []\n",
    "            f1 = []\n",
    "            for train_index, test_index in kf.split(data):        \n",
    "                x_train, y_train = data.Overview.iloc[train_index], data.genre_y.iloc[train_index]\n",
    "                x_test, y_test = data.Overview.iloc[test_index], data.genre_y.iloc[test_index]\n",
    "                pipe.fit(x_train, y_train)\n",
    "                y_pred = pipe.predict(x_test)\n",
    "                acc.append(np.mean(y_pred==y_test))\n",
    "                prec.append(precision_score(y_test, y_pred))\n",
    "                rec.append(recall_score(y_test, y_pred))\n",
    "                f1.append(f1_score(y_test, y_pred))\n",
    "            k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Action ('tfidf', 'sgdc', 'under')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Drama ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Comedy ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Animation ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Horror ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Adventure ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Thriller ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Family ('tfidf', 'logistic_regression', 'over')\n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Overfitting: iteration 1: \n",
      "Overfitting: iteration 2: \n",
      "Overfitting: iteration 3: \n",
      "Science Fiction ('tfidf', 'logistic_regression', 'over')\n"
     ]
    }
   ],
   "source": [
    "n_vec = len(vectorizer)\n",
    "n_clf = len(classifier)\n",
    "\n",
    "n_iterations = n_vec*n_clf\n",
    "\n",
    "temp = data.copy()\n",
    "\n",
    "test_result = {}\n",
    "\n",
    "for genre in genres[:9]:\n",
    "    temp['genre_y'] = [1 if y == genre else 0 for y in temp['Genres']]\n",
    "    k = 1\n",
    "    final_score = {}\n",
    "    for vect_name, vect in vectorizer.items():\n",
    "        for clf_name, clf in classifier.items():\n",
    "            kf = KFold(n_splits=3, random_state=None, shuffle=False)\n",
    "            \n",
    "            acc_normal = []\n",
    "            prec_normal = []\n",
    "            rec_normal = []\n",
    "            f1_normal = []\n",
    "            auc_normal = []\n",
    "            \n",
    "            acc_over = []\n",
    "            prec_over = []\n",
    "            rec_over = []\n",
    "            f1_over = []\n",
    "            auc_over = []\n",
    "            \n",
    "            acc_under = []\n",
    "            prec_under = []\n",
    "            rec_under = []\n",
    "            f1_under = []\n",
    "            auc_under = []\n",
    "            \n",
    "            i = 1\n",
    "            x, y = temp.Overview, temp.genre_y\n",
    "            for train_index, test_index in kf.split(data):\n",
    "                x_train, y_train = x.iloc[train_index], y.iloc[train_index]\n",
    "                x_test, y_test = x.iloc[test_index], y.iloc[test_index]\n",
    "                \n",
    "                train_vect = vect.fit_transform(x_train)\n",
    "                \n",
    "                clf.fit(train_vect, y_train)\n",
    "                \n",
    "                test_vect = vect.transform(x_test)\n",
    "                y_pred = clf.predict(test_vect)\n",
    "\n",
    "                acc_normal.append(np.mean(y_pred==y_test))\n",
    "                prec_normal.append(precision_score(y_test, y_pred))\n",
    "                rec_normal.append(recall_score(y_test, y_pred))\n",
    "                f1_normal.append(f1_score(y_test, y_pred))\n",
    "                auc_normal.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "                \n",
    "                train_vect_over, y_train_over = SMOTE().fit_resample(train_vect, y_train) \n",
    "                clf.fit(train_vect_over, y_train_over)\n",
    "                \n",
    "                test_vect = vect.transform(x_test)\n",
    "                y_pred = clf.predict(test_vect)\n",
    "\n",
    "                acc_over.append(np.mean(y_pred==y_test))\n",
    "                prec_over.append(precision_score(y_test, y_pred))\n",
    "                rec_over.append(recall_score(y_test, y_pred))\n",
    "                f1_over.append(f1_score(y_test, y_pred))\n",
    "                auc_over.append(roc_auc_score(y_test, y_pred))\n",
    "                #print('Overfitting: iteration ' + str(i) + ': ')\n",
    "                \n",
    "                train_vect_under, y_train_under = EditedNearestNeighbours().fit_resample(train_vect, y_train) \n",
    "                clf.fit(train_vect_under, y_train_under)\n",
    "                \n",
    "                test_vect = vect.transform(x_test)\n",
    "                y_pred = clf.predict(test_vect)\n",
    "\n",
    "                acc_under.append(np.mean(y_pred==y_test))\n",
    "                prec_under.append(precision_score(y_test, y_pred))\n",
    "                rec_under.append(recall_score(y_test, y_pred))\n",
    "                f1_under.append(f1_score(y_test, y_pred))\n",
    "                auc_under.append(roc_auc_score(y_test, y_pred))\n",
    "                i+=1\n",
    "            k+=1\n",
    "            final_score[(vect_name, clf_name, 'over')] = np.mean(auc_over)\n",
    "            final_score[(vect_name, clf_name, 'normal')] = np.mean(auc_normal)\n",
    "            final_score[(vect_name, clf_name, 'under')] = np.mean(auc_under)\n",
    "    test_result[genre] = max(final_score, key=final_score.get)\n",
    "    print(genre , test_result[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = {}\n",
    "for genre in genres[:9]:\n",
    "    data['genre_y'] = [1 if y == genre else 0 for y in data['Genres']]\n",
    "    vect_name = test_result[genre][0]\n",
    "    clf_name = test_result[genre][1]\n",
    "    sampling_name = test_result[genre][2]\n",
    "\n",
    "    vect = clone(vectorizer[vect_name])\n",
    "    clf = clone(classifier[clf_name])\n",
    "    \n",
    "    x_vect = vect.fit_transform(data.Overview)\n",
    "    \n",
    "    if sampling_name == 'normal':\n",
    "        clf.fit(x_vect, data.genre_y)\n",
    "    elif sampling_name == 'over':\n",
    "        x_vect, y = SMOTE().fit_resample(x_vect, data.genre_y)\n",
    "        clf.fit(x_vect, y)\n",
    "    elif sampling_name == 'under':\n",
    "        x_vect, y = EditedNearestNeighbours().fit_resample(x_vect, data.genre_y)\n",
    "        clf.fit(x_vect, y)\n",
    "    pipe_dict[genre] = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(s, pipe_dict):\n",
    "    genre_analyzed = []\n",
    "    proba = []\n",
    "    for genre, pipe in list(pipe_dict.items()):\n",
    "        print(genre, pipe)\n",
    "        res = pipe.predict_proba([s])\n",
    "        genre_analyzed.append(genre)\n",
    "        print(genre)\n",
    "        proba.append(res[0][1])\n",
    "        \n",
    "    data = pd.DataFrame({'genre': genre_analyzed, 'proba': proba})\n",
    "    data = data.sort_values(by='proba', ascending=True)\n",
    "    ax = data.plot(x='genre', y='proba', kind='barh')\n",
    "    print(genre_analyzed, proba)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Pipeline(steps=[('vect', TfidfVectorizer()), ('clf', SGDClassifier())])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "probability estimates are not available for loss='hinge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/1042649805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_genre\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fight\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/532175815.py\u001b[0m in \u001b[0;36mpredict_genre\u001b[1;34m(s, pipe_dict)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgenre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mgenre_analyzed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m# delegate only on instances, not the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# this is to allow access to the docstrings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# raise original `AttributeError` if `attr` does not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m# delegate only on instances, not the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# this is to allow access to the docstrings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"log\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"modified_huber\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m   1200\u001b[0m                 \u001b[1;34m\"probability estimates are not available for loss=%r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: probability estimates are not available for loss='hinge'"
     ]
    }
   ],
   "source": [
    "predict_genre(\"fight\", pipe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
